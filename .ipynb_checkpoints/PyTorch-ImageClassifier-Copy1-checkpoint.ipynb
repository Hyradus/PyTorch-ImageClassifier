{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PyTorch Image Classifier**\n",
    "Contacts: [g.nodjoumi@jacobs-university.de](mailto:g.nodjoumi@jacobs-university.de)\n",
    "\n",
    "A simple image classifier demo-notebook based on resnet50, to be further developed and used to filter very large dataset before labeling for object detection / image segmentation\n",
    "\n",
    "## **Dataset**\n",
    "Dataset must be organized according the following structure:\n",
    "- rootdir\n",
    "    - class1\n",
    "        - img1\n",
    "        - img2\n",
    "        - imgX \n",
    "        - ...\n",
    "        \n",
    "### **Example**     \n",
    "**E.g. data provided and used for this notebook**\n",
    "- ./Example_dataset\n",
    "    - Background\n",
    "        - ESP_011677_1655_RED_uint8_H0_V0__crop_H0_V1__cropped_cropped.png\n",
    "        - ...\n",
    "    - Craters\n",
    "        - ESP_011386_2065_RED_uint8_H0_V0__crop_H0_V2__cropped_cropped.png\n",
    "        - ...\n",
    "    - Skylights\n",
    "        - ESP_061680_1985_RED_print_H2_V0__crop_cropped.png\n",
    "        - ...\n",
    "        \n",
    "## How it works\n",
    "\n",
    "- All images are loaded and transformed\n",
    "- All images indexes are splitted into three sub-dataset indexes\n",
    "    - train (used for training)\n",
    "    - valid (used for validate the training)\n",
    "    - test (used to simulate real-world data)\n",
    "- Data distributions for sub-datasets are shown in pie charts\n",
    "- Train and valid indexes are used to load images and ingest into training routine\n",
    "- Test index is used to load unseen data\n",
    "- Test data are reandomly picked and predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data rootdir definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/media/gnodj/W-DATS/HiRiSE_Data/TEST_IMG_CLASSIFICATION_pytorch/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms definitions for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform ={ 'train': transforms.Compose([transforms.Resize(900),\n",
    "                                          transforms.CenterCrop(900),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomRotation([-90,90]),\n",
    "                                          transforms.ToTensor(),\n",
    "                                         # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          #                     std=[0.229, 0.224, 0.225])\n",
    "                                         ]),\n",
    "            'test':transforms.Compose([transforms.Resize(900),\n",
    "                                       transforms.CenterCrop(900),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                           #                    std=[0.229, 0.224, 0.225])\n",
    "                                      ]),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load of full dataset and retrevial of image indeses and classes from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = datasets.ImageFolder(datadir, transform=transform['train'])\n",
    "\n",
    "num_train = len(image_dataset)\n",
    "indices = list(range(num_train))\n",
    "print('Dataset contains:', len(image_dataset), ' elements distributed in: ',image_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ts, clss = map(list,zip(*image_dataset))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['class','type']\n",
    "DF = pd.DataFrame(columns=columns)\n",
    "DF['class']=clss\n",
    "classes = image_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(indices,\n",
    "                                          test_size=0.05,\n",
    "                                          shuffle=True,\n",
    "                                          stratify=DF['class'].values,\n",
    "                                          #stratify=DF['type'].values,\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_idx is further divided in proper train and valid indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(train_idx,\n",
    "                                          test_size=0.3,\n",
    "                                          shuffle=True,\n",
    "                                          stratify=DF['class'].loc[train_idx],\n",
    "                                          #stratify=DF.loc[train_data],\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Valid data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(image_dataset,\n",
    "               sampler=train_idx, batch_size=8,pin_memory=True)\n",
    "validloader = torch.utils.data.DataLoader(image_dataset,\n",
    "               sampler=valid_idx, batch_size=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[train_idx,'type']='TRAIN'\n",
    "DF.loc[test_idx,'type']='TEST'\n",
    "DF.loc[valid_idx,'type']='VALID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = classes\n",
    "plt.figure(figsize = (20,10), facecolor='white',dpi=300)\n",
    "\n",
    "plt.suptitle('Data distributions', fontsize=15)\n",
    "ax1 = plt.subplot2grid((1,3),(0,0))\n",
    "plt.pie(DF.loc[DF['type'] == 'TRAIN'].groupby('class').size(),\n",
    "        labels=label,autopct=lambda p:f'{p:.2f}%, \\n{p*len(train_idx)/100:.0f} Images',\n",
    "        shadow=False, startangle=90)\n",
    "plt.title('Train Data\\n{} Images'.format(len(train_idx), loc='center'))\n",
    "ax1 = plt.subplot2grid((1,3),(0,1))\n",
    "plt.pie(DF.loc[DF['type'] == 'VALID'].groupby('class').size(), \n",
    "        labels=label,autopct=lambda p:f'{p:.2f}%, \\n{p*len(valid_idx)/100:.0f} Images', \n",
    "        shadow=False, startangle=90)\n",
    "plt.title('Valid Data\\n{} Images'.format(len(valid_idx), loc='center'))\n",
    "ax1 = plt.subplot2grid((1,3),(0,2))\n",
    "plt.pie(DF.loc[DF['type'] == 'TEST'].groupby('class').size(), \n",
    "        labels=label,autopct=lambda p:f'{p:.2f}%, \\n{p*len(test_idx)/100:.0f} Images', \n",
    "        shadow=False, startangle=90)\n",
    "plt.title('Test Data\\n{} Images'.format(len(test_idx), loc='center'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preT = True\n",
    "model = models.resnet50(pretrained=True)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the pretrained layers if selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preT == True:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the last fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 10),\n",
    "                                 nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss criteria and otpimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the model to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses =  []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validloader:\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    valid_loss += batch_loss.item()\n",
    "                    \n",
    "                   # ps = torch.exp(logps)\n",
    "                    #top_p, top_class = ps.topk(1, dim=1)\n",
    "                    #equals = top_class == labels.view(*top_class.shape)\n",
    "                    #accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            valid_losses.append(valid_loss/len(validloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Valid loss: {valid_loss/len(validloader):.3f}.. \")\n",
    "                  #f\"Valid accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "torch.save(model, 'test_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'test_3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**\n",
    "Show training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader):\n",
    "        # tracking test loss\n",
    "    test_loss = 0.0\n",
    "    cls_correct = list(0. for i in range(len(classes)))\n",
    "    cls_totals = list(0. for i in range(len(classes)))\n",
    "\n",
    "    model.eval()  # it-disables-dropout\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()*images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_ts = predicted.eq(labels.data.view_as(predicted))\n",
    "            correct = np.squeeze(correct_ts.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_ts.cpu().numpy())\n",
    "            for i in range(len(labels)):\n",
    "                label = labels.data[i]\n",
    "                cls_correct[label] += correct[i].item()\n",
    "                cls_totals[label] += 1\n",
    "        test_loss = test_loss/len(dataloader.dataset)\n",
    "\n",
    "        print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            if cls_totals[i] > 0:\n",
    "                print(f'Accuracy of {classes[i]}: {round(100*cls_correct[i]/cls_totals[i], 2)}%')\n",
    "            else:\n",
    "                print(f'Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "\n",
    "\n",
    "    print(f'Full Accuracy: {round(100. * np.sum(cls_correct) / np.sum(cls_totals), 2)}% {np.sum(cls_correct)} out of {np.sum(cls_totals)}')\n",
    "\n",
    "    # Save \n",
    "    torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/media/gnodj/W-DATS/python_scripts/DeepLearning/PyTorch-ImageClassifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**\n",
    "Loading model for testing on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=torch.load('test_3.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Definition of functions**\n",
    "Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = transform['test'](image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get random images from test dataset using test indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(num, indice,test_dataset):\n",
    "    idx=np.random.choice(indice,num)\n",
    "    loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                   sampler=idx, batch_size=num,pin_memory=True)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels, idx, loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of all images using test transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(datadir, transform=transform['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil = transforms.ToPILImage()\n",
    "images, labels, idx, testloader= get_random_images(5, test_idx,test_dataset)\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "#    sub.set_title(str(classes[index]) + \":\" + str(res))\n",
    "    sub.set_title(str(classes[index]) + \":\" + str(res)+'\\n'+str(idx[ii])+'\\n'+str(index))\n",
    "\n",
    "    plt.axis('off')\n",
    "    #r_img = to_pil(test_data[ii][0])\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check to verify that test images have not been used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in idx:\n",
    "    if i in train_idx:\n",
    "        print(i, ' is used for training')\n",
    "    else:\n",
    "        print(i, ' is not used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/media/gnodj/W-DATS/HiRiSE_Data/ImageClassifier_test/png'+'/results'\n",
    "data_dir = '/media/gnodj/W-DATS/HiRiSE_Data/ImageClassifier_test/png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir(res_dir)\n",
    "    os.mkdir(res_dir+'/Unknown')\n",
    "    for j in image_dataset.classes:\n",
    "        os.mkdir(res_dir+'/'+j)\n",
    "        print(str(j))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenUtils import get_paths\n",
    "import os\n",
    "import glob\n",
    "\n",
    "file_paths = get_paths(data_dir+'/','png')\n",
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_imgs(num, indice, test_dataset):#, transform=transform['test']):\n",
    "    indices = indice\n",
    "    idx=np.random.choice(indices,num)\n",
    "    #idx = i[:num]\n",
    "    print(idx)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                   sampler=idx, batch_size=num,pin_memory=True)\n",
    "    \n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels, idx, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#css = list(range(0,len(image_dataset.classes)))\n",
    "from PIL import Image\n",
    "num = 5\n",
    "to_pil = transforms.ToPILImage()\n",
    "#imgs, lbls, indice, llder= rnd_imgs(10, idcs, new_dataset)\n",
    "fig=plt.figure(figsize=(30,20))\n",
    "start = time.time()\n",
    "#for ii in range(num):\n",
    "rnd_idx= np.random.choice(file_paths, num)\n",
    "for ii in range(len(rnd_idx)):\n",
    "#    image = to_pil(imgs[ii])\n",
    "    image= Image.open(rnd_idx[ii]).convert(\"RGB\")\n",
    "    index = predict_image(image)\n",
    "    sub = fig.add_subplot(1, num, ii+1)\n",
    "    sub.set_title(str(classes[index]) +'\\nImage:\\n:'+str(rnd_idx[ii])+'\\nIndex:'+str(index))\n",
    "    plt.axis('off')\n",
    "    #r_img = to_pil(test_data[ii][0])\n",
    "    plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
